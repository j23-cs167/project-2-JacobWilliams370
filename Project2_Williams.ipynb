{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j23-cs167/project-2-JacobWilliams370/blob/main/Project2_Williams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project #2\n",
        "##Name:\n",
        "\n",
        "Proposed Points (out of 25):"
      ],
      "metadata": {
        "id": "rIepkBIuT_Pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Points Attempted:** For this project, I attempted to achieve all the points (25/25) like I did for the first project. Below is a what I think I deserve for each category:\n",
        "\n",
        "Problem: 2/2\n",
        "\n",
        "Data Preparation: 2/2\n",
        "\n",
        "Research: 8/10\n",
        "\n",
        "Analysis: 10/10\n",
        "\n",
        "Bumps in the road: 1/1"
      ],
      "metadata": {
        "id": "v5-qDRPeGMy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Problem\n",
        "State the problem you are trying to solve with this machine learning experiment. Include a description of the data, where you got the data, and what you're trying to predict.."
      ],
      "metadata": {
        "id": "HbwKLNhzP8YO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When I was debating what I wanted to do for my final project, I couldn't decide if I wanted to do a typical regression or a CNN. A typical regression is what I would be doing most likely on later in my career, but I was fascinated by CNN's. Ultimately, I decided to go with the CNN because I've completed lots of regression research before and I thought working with a CNN would give me a better range of experience.\n",
        "\n",
        "Our dataset deals with osteoarthritis, which is a condition where the natural cushioning betweens our joints, cartilage slowly wears away. This can give a person pain and the bones of the joints rub together. Our dataset contains pictures of healthy knees and knees with osteoarthritis. Our training set contains **2350** observations and our testing set contains **845** observations. I pulled this dataset off kaggle and it has decent usability with 7.5 (https://www.kaggle.com/datasets/farjanakabirsamanta/osteoarthritis-prediction). Below is a description of our problem.\n",
        "\n",
        "**Problem:** How accurately can we predict whether or not a person has osteoarthritis in their knees using a CNN?"
      ],
      "metadata": {
        "id": "LwseoUsMmCz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Preparation\n",
        "Explain your data preparation. What did you have to do to get your data in shape for your experiments? Why are you certain that you data is clean and prepared for use in your algorithms?"
      ],
      "metadata": {
        "id": "qR_foVOeQVL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are using a CNN, I don't believe there is much I have to do to prep our data since it deals with pictures. Thus, we do not deal with missing data here. \n",
        "\n",
        "Thus, to make our data usable we need to split our dataset into testing and training. Below, I read in the separate training and testing datasets. Then I used the functions below to ensure our separate training and test datasets were read in correctly. \n",
        "\n",
        "Although, we do not need to necessarily deal with missing data, there are steps we must take to ensure our dataset is usable. We first we to specifiy the image dimensions for width and length, which are 200. Next, we need to determine the batch size to feed into our neural network, which we will use 32. Lastly, we need to rescale our pixel values, which range from 0 to 255, between 0 and 1.\n",
        "\n",
        "After these steps, I'm confident that our data is clean and ready to be used. "
      ],
      "metadata": {
        "id": "aMDJDnW_mOWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load and prepare your data here\n",
        "import keras\n",
        "import tensorflow \n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import sys\n",
        "\n",
        "## Connect to Drive\n",
        "from google.colab import drive\n",
        "import pandas\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "## Image dimensions\n",
        "img_width = 200\n",
        "img_height = 200\n",
        "\n",
        "## Directories for testing and training data\n",
        "train_data_dir = '/content/drive/MyDrive/CS167/datasets/osteo_data1/train/train' \n",
        "test_data_dir = '/content/drive/MyDrive/CS167/datasets/osteo_data1/test/test'\n",
        "\n",
        "## To feed the training images to the neural network in batches of 32 images at a time\n",
        "batch_size = 32\n",
        "\n",
        "## Rescale pixel values from [0, 255] to between 0 and 1\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "## Look for training and testing data and figure out the class of each example based on subfolder\n",
        "train_data = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_data = datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')"
      ],
      "metadata": {
        "id": "9dUdBChRmKxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4d380a-6ba2-42bd-e768-7cdd824b9959"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 2350 images belonging to 2 classes.\n",
            "Found 845 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O8zA5YlvZFV",
        "outputId": "2dbba4d2-7d05-4304-cf79-cd6b64ccc380"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Research\n",
        "\n",
        "Put your code and your experiments here."
      ],
      "metadata": {
        "id": "Hc7HMmNPR10W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code goes here... don't forget to include graphs. Professor Urness loves graphs."
      ],
      "metadata": {
        "id": "XfaACsEOR4U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape=(img_width, img_height, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation = 'relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "# need to compile the model before you can use it\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "training_results = model.fit_generator(\n",
        "        train_data, #training set\n",
        "        steps_per_epoch = len(train_data), \n",
        "        epochs=75, #number of epochs \n",
        "        validation_data = test_data, #testing set\n",
        "        validation_steps = len(test_data)\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Tcfp1GHvn3Z",
        "outputId": "405f0254-8169-4b3b-835a-b3be28d44b30"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 198, 198, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 99, 99, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 97, 97, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 48, 48, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 73728)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                4718656   \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,728,865\n",
            "Trainable params: 4,728,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-e103118e4192>:18: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  training_results = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 11s 143ms/step - loss: 0.6405 - accuracy: 0.6409 - val_loss: 0.8987 - val_accuracy: 0.3254\n",
            "Epoch 2/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.5971 - accuracy: 0.6626 - val_loss: 1.2763 - val_accuracy: 0.3266\n",
            "Epoch 3/75\n",
            "74/74 [==============================] - 11s 152ms/step - loss: 0.5950 - accuracy: 0.6647 - val_loss: 0.9753 - val_accuracy: 0.3266\n",
            "Epoch 4/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.5895 - accuracy: 0.6553 - val_loss: 1.4062 - val_accuracy: 0.3266\n",
            "Epoch 5/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.5589 - accuracy: 0.6736 - val_loss: 1.9706 - val_accuracy: 0.3302\n",
            "Epoch 6/75\n",
            "74/74 [==============================] - 11s 142ms/step - loss: 0.5312 - accuracy: 0.6949 - val_loss: 1.7722 - val_accuracy: 0.3266\n",
            "Epoch 7/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.5242 - accuracy: 0.7191 - val_loss: 1.9762 - val_accuracy: 0.3195\n",
            "Epoch 8/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.5057 - accuracy: 0.7153 - val_loss: 2.7855 - val_accuracy: 0.3254\n",
            "Epoch 9/75\n",
            "74/74 [==============================] - 10s 141ms/step - loss: 0.5696 - accuracy: 0.6689 - val_loss: 1.5994 - val_accuracy: 0.3290\n",
            "Epoch 10/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.4951 - accuracy: 0.7264 - val_loss: 2.2754 - val_accuracy: 0.3207\n",
            "Epoch 11/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.4833 - accuracy: 0.7417 - val_loss: 2.2867 - val_accuracy: 0.3231\n",
            "Epoch 12/75\n",
            "74/74 [==============================] - 10s 141ms/step - loss: 0.4720 - accuracy: 0.7591 - val_loss: 2.4352 - val_accuracy: 0.3456\n",
            "Epoch 13/75\n",
            "74/74 [==============================] - 10s 141ms/step - loss: 0.4677 - accuracy: 0.7609 - val_loss: 2.4970 - val_accuracy: 0.3373\n",
            "Epoch 14/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.4473 - accuracy: 0.7821 - val_loss: 3.0578 - val_accuracy: 0.3278\n",
            "Epoch 15/75\n",
            "74/74 [==============================] - 10s 141ms/step - loss: 0.4266 - accuracy: 0.7911 - val_loss: 2.6868 - val_accuracy: 0.3290\n",
            "Epoch 16/75\n",
            "74/74 [==============================] - 10s 138ms/step - loss: 0.4662 - accuracy: 0.7587 - val_loss: 2.6902 - val_accuracy: 0.3290\n",
            "Epoch 17/75\n",
            "74/74 [==============================] - 11s 143ms/step - loss: 0.4104 - accuracy: 0.8102 - val_loss: 2.6333 - val_accuracy: 0.3396\n",
            "Epoch 18/75\n",
            "74/74 [==============================] - 10s 142ms/step - loss: 0.3820 - accuracy: 0.8230 - val_loss: 2.7519 - val_accuracy: 0.3467\n",
            "Epoch 19/75\n",
            "74/74 [==============================] - 10s 138ms/step - loss: 0.4424 - accuracy: 0.7834 - val_loss: 2.7011 - val_accuracy: 0.3290\n",
            "Epoch 20/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.3793 - accuracy: 0.8234 - val_loss: 3.2084 - val_accuracy: 0.3373\n",
            "Epoch 21/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.3992 - accuracy: 0.8055 - val_loss: 2.7132 - val_accuracy: 0.3373\n",
            "Epoch 22/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.3729 - accuracy: 0.8170 - val_loss: 3.5580 - val_accuracy: 0.3325\n",
            "Epoch 23/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.3749 - accuracy: 0.8247 - val_loss: 3.9603 - val_accuracy: 0.3325\n",
            "Epoch 24/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.3533 - accuracy: 0.8362 - val_loss: 3.3558 - val_accuracy: 0.3432\n",
            "Epoch 25/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.3719 - accuracy: 0.8213 - val_loss: 2.6879 - val_accuracy: 0.3420\n",
            "Epoch 26/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.3423 - accuracy: 0.8460 - val_loss: 2.8541 - val_accuracy: 0.3479\n",
            "Epoch 27/75\n",
            "74/74 [==============================] - 11s 152ms/step - loss: 0.3222 - accuracy: 0.8562 - val_loss: 4.1155 - val_accuracy: 0.3503\n",
            "Epoch 28/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.3518 - accuracy: 0.8374 - val_loss: 2.7149 - val_accuracy: 0.3503\n",
            "Epoch 29/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.3258 - accuracy: 0.8515 - val_loss: 4.0822 - val_accuracy: 0.3314\n",
            "Epoch 30/75\n",
            "74/74 [==============================] - 11s 143ms/step - loss: 0.3284 - accuracy: 0.8549 - val_loss: 3.8206 - val_accuracy: 0.3420\n",
            "Epoch 31/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.3158 - accuracy: 0.8613 - val_loss: 3.8465 - val_accuracy: 0.3538\n",
            "Epoch 32/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.3274 - accuracy: 0.8596 - val_loss: 3.6116 - val_accuracy: 0.3432\n",
            "Epoch 33/75\n",
            "74/74 [==============================] - 10s 141ms/step - loss: 0.3106 - accuracy: 0.8634 - val_loss: 3.7797 - val_accuracy: 0.3527\n",
            "Epoch 34/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.3119 - accuracy: 0.8596 - val_loss: 4.0027 - val_accuracy: 0.3503\n",
            "Epoch 35/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.3255 - accuracy: 0.8630 - val_loss: 3.8410 - val_accuracy: 0.3396\n",
            "Epoch 36/75\n",
            "74/74 [==============================] - 10s 141ms/step - loss: 0.3317 - accuracy: 0.8591 - val_loss: 4.7043 - val_accuracy: 0.3491\n",
            "Epoch 37/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.2967 - accuracy: 0.8698 - val_loss: 4.3477 - val_accuracy: 0.3538\n",
            "Epoch 38/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.2825 - accuracy: 0.8728 - val_loss: 5.1386 - val_accuracy: 0.3349\n",
            "Epoch 39/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.3127 - accuracy: 0.8655 - val_loss: 4.0469 - val_accuracy: 0.3515\n",
            "Epoch 40/75\n",
            "74/74 [==============================] - 11s 151ms/step - loss: 0.2914 - accuracy: 0.8685 - val_loss: 3.9657 - val_accuracy: 0.3562\n",
            "Epoch 41/75\n",
            "74/74 [==============================] - 10s 137ms/step - loss: 0.2976 - accuracy: 0.8723 - val_loss: 3.9220 - val_accuracy: 0.3527\n",
            "Epoch 42/75\n",
            "74/74 [==============================] - 10s 141ms/step - loss: 0.2796 - accuracy: 0.8779 - val_loss: 4.5900 - val_accuracy: 0.3550\n",
            "Epoch 43/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.3334 - accuracy: 0.8451 - val_loss: 3.8155 - val_accuracy: 0.3550\n",
            "Epoch 44/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.2911 - accuracy: 0.8762 - val_loss: 3.8352 - val_accuracy: 0.3527\n",
            "Epoch 45/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.3103 - accuracy: 0.8523 - val_loss: 4.0648 - val_accuracy: 0.3562\n",
            "Epoch 46/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.2903 - accuracy: 0.8766 - val_loss: 3.7908 - val_accuracy: 0.3550\n",
            "Epoch 47/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.2809 - accuracy: 0.8830 - val_loss: 3.7547 - val_accuracy: 0.3562\n",
            "Epoch 48/75\n",
            "74/74 [==============================] - 10s 141ms/step - loss: 0.2978 - accuracy: 0.8736 - val_loss: 3.8738 - val_accuracy: 0.3503\n",
            "Epoch 49/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.2804 - accuracy: 0.8770 - val_loss: 3.8077 - val_accuracy: 0.3503\n",
            "Epoch 50/75\n",
            "74/74 [==============================] - 10s 138ms/step - loss: 0.2637 - accuracy: 0.8817 - val_loss: 4.5589 - val_accuracy: 0.3527\n",
            "Epoch 51/75\n",
            "74/74 [==============================] - 10s 141ms/step - loss: 0.2857 - accuracy: 0.8787 - val_loss: 4.1575 - val_accuracy: 0.3456\n",
            "Epoch 52/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.2639 - accuracy: 0.8923 - val_loss: 4.8809 - val_accuracy: 0.3503\n",
            "Epoch 53/75\n",
            "74/74 [==============================] - 11s 151ms/step - loss: 0.2570 - accuracy: 0.8949 - val_loss: 4.7432 - val_accuracy: 0.3574\n",
            "Epoch 54/75\n",
            "74/74 [==============================] - 10s 141ms/step - loss: 0.2533 - accuracy: 0.8923 - val_loss: 4.6653 - val_accuracy: 0.3550\n",
            "Epoch 55/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.2472 - accuracy: 0.8953 - val_loss: 5.0933 - val_accuracy: 0.3444\n",
            "Epoch 56/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.2607 - accuracy: 0.8877 - val_loss: 4.9417 - val_accuracy: 0.3550\n",
            "Epoch 57/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.2687 - accuracy: 0.8855 - val_loss: 5.0630 - val_accuracy: 0.3550\n",
            "Epoch 58/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.2501 - accuracy: 0.8923 - val_loss: 3.9112 - val_accuracy: 0.3550\n",
            "Epoch 59/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.2737 - accuracy: 0.8821 - val_loss: 3.8825 - val_accuracy: 0.3598\n",
            "Epoch 60/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.2313 - accuracy: 0.9021 - val_loss: 4.2320 - val_accuracy: 0.3598\n",
            "Epoch 61/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.2798 - accuracy: 0.8787 - val_loss: 4.6909 - val_accuracy: 0.3420\n",
            "Epoch 62/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.2365 - accuracy: 0.9004 - val_loss: 5.1500 - val_accuracy: 0.3550\n",
            "Epoch 63/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.2381 - accuracy: 0.9055 - val_loss: 4.7717 - val_accuracy: 0.3586\n",
            "Epoch 64/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.2287 - accuracy: 0.9000 - val_loss: 4.6001 - val_accuracy: 0.3609\n",
            "Epoch 65/75\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.2247 - accuracy: 0.9068 - val_loss: 4.8151 - val_accuracy: 0.3586\n",
            "Epoch 66/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.2352 - accuracy: 0.8966 - val_loss: 4.0434 - val_accuracy: 0.3598\n",
            "Epoch 67/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.2321 - accuracy: 0.9106 - val_loss: 4.0928 - val_accuracy: 0.3633\n",
            "Epoch 68/75\n",
            "74/74 [==============================] - 10s 141ms/step - loss: 0.2357 - accuracy: 0.9038 - val_loss: 5.2056 - val_accuracy: 0.3527\n",
            "Epoch 69/75\n",
            "74/74 [==============================] - 10s 138ms/step - loss: 0.2160 - accuracy: 0.9119 - val_loss: 5.5114 - val_accuracy: 0.3491\n",
            "Epoch 70/75\n",
            "74/74 [==============================] - 10s 138ms/step - loss: 0.2194 - accuracy: 0.9064 - val_loss: 4.9179 - val_accuracy: 0.3538\n",
            "Epoch 71/75\n",
            "74/74 [==============================] - 10s 140ms/step - loss: 0.2189 - accuracy: 0.9132 - val_loss: 4.9373 - val_accuracy: 0.3586\n",
            "Epoch 72/75\n",
            "74/74 [==============================] - 10s 139ms/step - loss: 0.2063 - accuracy: 0.9153 - val_loss: 4.2255 - val_accuracy: 0.3586\n",
            "Epoch 73/75\n",
            "74/74 [==============================] - 11s 143ms/step - loss: 0.2422 - accuracy: 0.8945 - val_loss: 4.7205 - val_accuracy: 0.3598\n",
            "Epoch 74/75\n",
            "74/74 [==============================] - 11s 145ms/step - loss: 0.2294 - accuracy: 0.9038 - val_loss: 5.1507 - val_accuracy: 0.3467\n",
            "Epoch 75/75\n",
            "74/74 [==============================] - 11s 146ms/step - loss: 0.2265 - accuracy: 0.9055 - val_loss: 4.8860 - val_accuracy: 0.3586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our first model appears to be underfitting."
      ],
      "metadata": {
        "id": "q4sVFA3PG0dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normal CNN Graph\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(training_results.history['accuracy'])\n",
        "plt.plot(training_results.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ccN6TQFCvp4G",
        "outputId": "22448247-d867-4bc8-d2b8-4b4103dfa540"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuned CNN\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, (3, 3), activation = 'relu', input_shape=(img_width, img_height, 3)))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model2.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model2.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3),activation = 'relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(64,activation = 'relu'))\n",
        "model2.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "# need to compile the model before you can use it\n",
        "opt = SGD(lr=0.05, momentum=0.9)\n",
        "model2.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "training_results2 = model2.fit_generator(\n",
        "        train_data, #training set\n",
        "        steps_per_epoch = len(train_data), \n",
        "        epochs=100, #number of epochs \n",
        "        validation_data = test_data, #testing set\n",
        "        validation_steps = len(test_data)\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuHHRXx2v1Yw",
        "outputId": "0666fcbd-0e9f-4b3f-c23e-81ef813a02ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_22 (Conv2D)          (None, 198, 198, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 99, 99, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 97, 97, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 48, 48, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 46, 46, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 23, 23, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 21, 21, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                409664    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 447,617\n",
            "Trainable params: 447,617\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-cfdc3ce4e42c>:25: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  training_results2 = model2.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 12s 162ms/step - loss: 0.6537 - accuracy: 0.6515 - val_loss: 0.8433 - val_accuracy: 0.3266\n",
            "Epoch 2/100\n",
            "74/74 [==============================] - 11s 152ms/step - loss: 0.6410 - accuracy: 0.6553 - val_loss: 1.0405 - val_accuracy: 0.3266\n",
            "Epoch 3/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.5979 - accuracy: 0.6523 - val_loss: 1.4178 - val_accuracy: 0.3302\n",
            "Epoch 4/100\n",
            "74/74 [==============================] - 11s 150ms/step - loss: 0.5822 - accuracy: 0.6540 - val_loss: 2.8869 - val_accuracy: 0.3266\n",
            "Epoch 5/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.5789 - accuracy: 0.6506 - val_loss: 3.4445 - val_accuracy: 0.3266\n",
            "Epoch 6/100\n",
            "74/74 [==============================] - 11s 150ms/step - loss: 0.5690 - accuracy: 0.6591 - val_loss: 2.7102 - val_accuracy: 0.3361\n",
            "Epoch 7/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.5626 - accuracy: 0.6613 - val_loss: 3.4342 - val_accuracy: 0.3385\n",
            "Epoch 8/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.5559 - accuracy: 0.6604 - val_loss: 4.3728 - val_accuracy: 0.3314\n",
            "Epoch 9/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.5615 - accuracy: 0.6562 - val_loss: 5.5374 - val_accuracy: 0.3290\n",
            "Epoch 10/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.5618 - accuracy: 0.6566 - val_loss: 3.0651 - val_accuracy: 0.3456\n",
            "Epoch 11/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.5507 - accuracy: 0.6621 - val_loss: 3.3474 - val_accuracy: 0.3290\n",
            "Epoch 12/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.5459 - accuracy: 0.6579 - val_loss: 5.0358 - val_accuracy: 0.3302\n",
            "Epoch 13/100\n",
            "74/74 [==============================] - 11s 150ms/step - loss: 0.5379 - accuracy: 0.6681 - val_loss: 3.7451 - val_accuracy: 0.3325\n",
            "Epoch 14/100\n",
            "74/74 [==============================] - 12s 161ms/step - loss: 0.5378 - accuracy: 0.6740 - val_loss: 2.2131 - val_accuracy: 0.3515\n",
            "Epoch 15/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.5254 - accuracy: 0.7034 - val_loss: 5.0880 - val_accuracy: 0.3373\n",
            "Epoch 16/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.4987 - accuracy: 0.7268 - val_loss: 2.4066 - val_accuracy: 0.3515\n",
            "Epoch 17/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.5229 - accuracy: 0.6987 - val_loss: 5.2122 - val_accuracy: 0.3432\n",
            "Epoch 18/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.4952 - accuracy: 0.7298 - val_loss: 4.8271 - val_accuracy: 0.3302\n",
            "Epoch 19/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.5078 - accuracy: 0.7145 - val_loss: 4.0044 - val_accuracy: 0.3420\n",
            "Epoch 20/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.4931 - accuracy: 0.7226 - val_loss: 4.9590 - val_accuracy: 0.3385\n",
            "Epoch 21/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.4921 - accuracy: 0.7506 - val_loss: 3.7147 - val_accuracy: 0.3373\n",
            "Epoch 22/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.4755 - accuracy: 0.7647 - val_loss: 2.5340 - val_accuracy: 0.3538\n",
            "Epoch 23/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.4594 - accuracy: 0.7613 - val_loss: 4.9273 - val_accuracy: 0.3467\n",
            "Epoch 24/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.4206 - accuracy: 0.7915 - val_loss: 6.8838 - val_accuracy: 0.3373\n",
            "Epoch 25/100\n",
            "74/74 [==============================] - 11s 145ms/step - loss: 0.4359 - accuracy: 0.7860 - val_loss: 3.7116 - val_accuracy: 0.3349\n",
            "Epoch 26/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.4233 - accuracy: 0.7860 - val_loss: 6.1840 - val_accuracy: 0.3408\n",
            "Epoch 27/100\n",
            "74/74 [==============================] - 12s 158ms/step - loss: 0.4422 - accuracy: 0.7787 - val_loss: 6.4483 - val_accuracy: 0.3491\n",
            "Epoch 28/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.5266 - accuracy: 0.6983 - val_loss: 3.6872 - val_accuracy: 0.3396\n",
            "Epoch 29/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.5461 - accuracy: 0.6851 - val_loss: 2.9477 - val_accuracy: 0.3302\n",
            "Epoch 30/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.5262 - accuracy: 0.6949 - val_loss: 3.2531 - val_accuracy: 0.3408\n",
            "Epoch 31/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.6124 - accuracy: 0.6753 - val_loss: 0.8467 - val_accuracy: 0.3266\n",
            "Epoch 32/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6465 - accuracy: 0.6553 - val_loss: 0.8639 - val_accuracy: 0.3266\n",
            "Epoch 33/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6456 - accuracy: 0.6553 - val_loss: 0.8186 - val_accuracy: 0.3266\n",
            "Epoch 34/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6469 - accuracy: 0.6553 - val_loss: 0.8764 - val_accuracy: 0.3266\n",
            "Epoch 35/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6494 - accuracy: 0.6553 - val_loss: 0.9257 - val_accuracy: 0.3266\n",
            "Epoch 36/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6490 - accuracy: 0.6553 - val_loss: 0.9078 - val_accuracy: 0.3266\n",
            "Epoch 37/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6464 - accuracy: 0.6553 - val_loss: 0.8328 - val_accuracy: 0.3266\n",
            "Epoch 38/100\n",
            "74/74 [==============================] - 12s 157ms/step - loss: 0.6476 - accuracy: 0.6553 - val_loss: 0.9011 - val_accuracy: 0.3266\n",
            "Epoch 39/100\n",
            "74/74 [==============================] - 11s 153ms/step - loss: 0.6472 - accuracy: 0.6553 - val_loss: 0.8284 - val_accuracy: 0.3266\n",
            "Epoch 40/100\n",
            "74/74 [==============================] - 11s 153ms/step - loss: 0.6444 - accuracy: 0.6553 - val_loss: 0.8598 - val_accuracy: 0.3266\n",
            "Epoch 41/100\n",
            "74/74 [==============================] - 11s 151ms/step - loss: 0.6469 - accuracy: 0.6553 - val_loss: 0.8018 - val_accuracy: 0.3266\n",
            "Epoch 42/100\n",
            "74/74 [==============================] - 11s 150ms/step - loss: 0.6482 - accuracy: 0.6553 - val_loss: 0.8257 - val_accuracy: 0.3266\n",
            "Epoch 43/100\n",
            "74/74 [==============================] - 11s 150ms/step - loss: 0.6458 - accuracy: 0.6553 - val_loss: 0.8143 - val_accuracy: 0.3266\n",
            "Epoch 44/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8371 - val_accuracy: 0.3266\n",
            "Epoch 45/100\n",
            "74/74 [==============================] - 11s 150ms/step - loss: 0.6445 - accuracy: 0.6553 - val_loss: 0.8777 - val_accuracy: 0.3266\n",
            "Epoch 46/100\n",
            "74/74 [==============================] - 11s 151ms/step - loss: 0.6446 - accuracy: 0.6553 - val_loss: 0.8774 - val_accuracy: 0.3266\n",
            "Epoch 47/100\n",
            "74/74 [==============================] - 11s 150ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8617 - val_accuracy: 0.3266\n",
            "Epoch 48/100\n",
            "74/74 [==============================] - 11s 151ms/step - loss: 0.6457 - accuracy: 0.6553 - val_loss: 0.8900 - val_accuracy: 0.3266\n",
            "Epoch 49/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6462 - accuracy: 0.6553 - val_loss: 0.8428 - val_accuracy: 0.3266\n",
            "Epoch 50/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6454 - accuracy: 0.6553 - val_loss: 0.8603 - val_accuracy: 0.3266\n",
            "Epoch 51/100\n",
            "74/74 [==============================] - 12s 160ms/step - loss: 0.6448 - accuracy: 0.6553 - val_loss: 0.8911 - val_accuracy: 0.3266\n",
            "Epoch 52/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.6449 - accuracy: 0.6553 - val_loss: 0.8813 - val_accuracy: 0.3266\n",
            "Epoch 53/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6457 - accuracy: 0.6553 - val_loss: 0.8569 - val_accuracy: 0.3266\n",
            "Epoch 54/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6454 - accuracy: 0.6553 - val_loss: 0.8921 - val_accuracy: 0.3266\n",
            "Epoch 55/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8700 - val_accuracy: 0.3266\n",
            "Epoch 56/100\n",
            "74/74 [==============================] - 11s 151ms/step - loss: 0.6449 - accuracy: 0.6553 - val_loss: 0.8708 - val_accuracy: 0.3266\n",
            "Epoch 57/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.6459 - accuracy: 0.6553 - val_loss: 0.8495 - val_accuracy: 0.3266\n",
            "Epoch 58/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6447 - accuracy: 0.6553 - val_loss: 0.8347 - val_accuracy: 0.3266\n",
            "Epoch 59/100\n",
            "74/74 [==============================] - 11s 146ms/step - loss: 0.6456 - accuracy: 0.6553 - val_loss: 0.8919 - val_accuracy: 0.3266\n",
            "Epoch 60/100\n",
            "74/74 [==============================] - 11s 150ms/step - loss: 0.6466 - accuracy: 0.6553 - val_loss: 0.8684 - val_accuracy: 0.3266\n",
            "Epoch 61/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6454 - accuracy: 0.6553 - val_loss: 0.8473 - val_accuracy: 0.3266\n",
            "Epoch 62/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6446 - accuracy: 0.6553 - val_loss: 0.8652 - val_accuracy: 0.3266\n",
            "Epoch 63/100\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.6442 - accuracy: 0.6553 - val_loss: 0.9007 - val_accuracy: 0.3266\n",
            "Epoch 64/100\n",
            "74/74 [==============================] - 11s 150ms/step - loss: 0.6454 - accuracy: 0.6553 - val_loss: 0.8510 - val_accuracy: 0.3266\n",
            "Epoch 65/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6461 - accuracy: 0.6553 - val_loss: 0.8837 - val_accuracy: 0.3266\n",
            "Epoch 66/100\n",
            "74/74 [==============================] - 11s 152ms/step - loss: 0.6451 - accuracy: 0.6553 - val_loss: 0.8331 - val_accuracy: 0.3266\n",
            "Epoch 67/100\n",
            "74/74 [==============================] - 11s 152ms/step - loss: 0.6449 - accuracy: 0.6553 - val_loss: 0.8504 - val_accuracy: 0.3266\n",
            "Epoch 68/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6458 - accuracy: 0.6553 - val_loss: 0.8637 - val_accuracy: 0.3266\n",
            "Epoch 69/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8661 - val_accuracy: 0.3266\n",
            "Epoch 70/100\n",
            "74/74 [==============================] - 11s 150ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8316 - val_accuracy: 0.3266\n",
            "Epoch 71/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8860 - val_accuracy: 0.3266\n",
            "Epoch 72/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6442 - accuracy: 0.6553 - val_loss: 0.8135 - val_accuracy: 0.3266\n",
            "Epoch 73/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6444 - accuracy: 0.6553 - val_loss: 0.8865 - val_accuracy: 0.3266\n",
            "Epoch 74/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.6451 - accuracy: 0.6553 - val_loss: 0.8448 - val_accuracy: 0.3266\n",
            "Epoch 75/100\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6457 - accuracy: 0.6553 - val_loss: 0.8330 - val_accuracy: 0.3266\n",
            "Epoch 76/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8590 - val_accuracy: 0.3266\n",
            "Epoch 77/100\n",
            "74/74 [==============================] - 12s 160ms/step - loss: 0.6442 - accuracy: 0.6553 - val_loss: 0.8235 - val_accuracy: 0.3266\n",
            "Epoch 78/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.6452 - accuracy: 0.6553 - val_loss: 0.8700 - val_accuracy: 0.3266\n",
            "Epoch 79/100\n",
            "74/74 [==============================] - 11s 146ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8752 - val_accuracy: 0.3266\n",
            "Epoch 80/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6440 - accuracy: 0.6553 - val_loss: 0.8320 - val_accuracy: 0.3266\n",
            "Epoch 81/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.6453 - accuracy: 0.6553 - val_loss: 0.8590 - val_accuracy: 0.3266\n",
            "Epoch 82/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6443 - accuracy: 0.6553 - val_loss: 0.8401 - val_accuracy: 0.3266\n",
            "Epoch 83/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6448 - accuracy: 0.6553 - val_loss: 0.8341 - val_accuracy: 0.3266\n",
            "Epoch 84/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6458 - accuracy: 0.6553 - val_loss: 0.8523 - val_accuracy: 0.3266\n",
            "Epoch 85/100\n",
            "74/74 [==============================] - 11s 146ms/step - loss: 0.6448 - accuracy: 0.6553 - val_loss: 0.8417 - val_accuracy: 0.3266\n",
            "Epoch 86/100\n",
            "74/74 [==============================] - 11s 146ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8621 - val_accuracy: 0.3266\n",
            "Epoch 87/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.6452 - accuracy: 0.6553 - val_loss: 0.8782 - val_accuracy: 0.3266\n",
            "Epoch 88/100\n",
            "74/74 [==============================] - 11s 146ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8402 - val_accuracy: 0.3266\n",
            "Epoch 89/100\n",
            "74/74 [==============================] - 12s 157ms/step - loss: 0.6467 - accuracy: 0.6553 - val_loss: 0.9171 - val_accuracy: 0.3266\n",
            "Epoch 90/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6454 - accuracy: 0.6553 - val_loss: 0.8946 - val_accuracy: 0.3266\n",
            "Epoch 91/100\n",
            "74/74 [==============================] - 11s 146ms/step - loss: 0.6455 - accuracy: 0.6553 - val_loss: 0.8674 - val_accuracy: 0.3266\n",
            "Epoch 92/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.6448 - accuracy: 0.6553 - val_loss: 0.8570 - val_accuracy: 0.3266\n",
            "Epoch 93/100\n",
            "74/74 [==============================] - 11s 150ms/step - loss: 0.6458 - accuracy: 0.6553 - val_loss: 0.8410 - val_accuracy: 0.3266\n",
            "Epoch 94/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6440 - accuracy: 0.6553 - val_loss: 0.8875 - val_accuracy: 0.3266\n",
            "Epoch 95/100\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6468 - accuracy: 0.6553 - val_loss: 0.8484 - val_accuracy: 0.3266\n",
            "Epoch 96/100\n",
            "74/74 [==============================] - 11s 151ms/step - loss: 0.6448 - accuracy: 0.6553 - val_loss: 0.8475 - val_accuracy: 0.3266\n",
            "Epoch 97/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.6446 - accuracy: 0.6553 - val_loss: 0.8498 - val_accuracy: 0.3266\n",
            "Epoch 98/100\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.6448 - accuracy: 0.6553 - val_loss: 0.8441 - val_accuracy: 0.3266\n",
            "Epoch 99/100\n",
            "74/74 [==============================] - 11s 146ms/step - loss: 0.6447 - accuracy: 0.6553 - val_loss: 0.8659 - val_accuracy: 0.3266\n",
            "Epoch 100/100\n",
            "74/74 [==============================] - 11s 146ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8679 - val_accuracy: 0.3266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(training_results2.history['accuracy'])\n",
        "plt.plot(training_results2.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "a18WCZOTv2he",
        "outputId": "1f3ad32b-8e72-4f69-d6c2-d810fc58f66a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuned CNN\n",
        "model3 = Sequential()\n",
        "model3.add(Conv2D(32, (3, 3), activation = 'relu', input_shape=(img_width, img_height, 3)))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model3.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model3.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model3.add(Conv2D(64, (3, 3),activation = 'relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(64,activation = 'relu'))\n",
        "model3.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "# need to compile the model before you can use it\n",
        "opt = SGD(lr=0.005, momentum=0.9)\n",
        "model3.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model3.summary()\n",
        "\n",
        "training_results3 = model2.fit_generator(\n",
        "        train_data, #training set\n",
        "        steps_per_epoch = len(train_data), \n",
        "        epochs=50, #number of epochs \n",
        "        validation_data = test_data, #testing set\n",
        "        validation_steps = len(test_data)\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMy8JFTMuMvA",
        "outputId": "af86ffdd-b85f-4950-ac46-7dbbe7d0486f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_34 (Conv2D)          (None, 198, 198, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 99, 99, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 97, 97, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 48, 48, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 46, 46, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 23, 23, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 21, 21, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                409664    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 447,617\n",
            "Trainable params: 447,617\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n",
            "<ipython-input-12-101f4a6733c6>:25: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  training_results3 = model2.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8605 - val_accuracy: 0.3266\n",
            "Epoch 2/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6448 - accuracy: 0.6553 - val_loss: 0.8304 - val_accuracy: 0.3266\n",
            "Epoch 3/50\n",
            "74/74 [==============================] - 12s 160ms/step - loss: 0.6456 - accuracy: 0.6553 - val_loss: 0.8247 - val_accuracy: 0.3266\n",
            "Epoch 4/50\n",
            "74/74 [==============================] - 12s 161ms/step - loss: 0.6460 - accuracy: 0.6553 - val_loss: 0.8363 - val_accuracy: 0.3266\n",
            "Epoch 5/50\n",
            "74/74 [==============================] - 12s 162ms/step - loss: 0.6449 - accuracy: 0.6553 - val_loss: 0.8866 - val_accuracy: 0.3266\n",
            "Epoch 6/50\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.6444 - accuracy: 0.6553 - val_loss: 0.8563 - val_accuracy: 0.3266\n",
            "Epoch 7/50\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8239 - val_accuracy: 0.3266\n",
            "Epoch 8/50\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6454 - accuracy: 0.6553 - val_loss: 0.8473 - val_accuracy: 0.3266\n",
            "Epoch 9/50\n",
            "74/74 [==============================] - 11s 153ms/step - loss: 0.6461 - accuracy: 0.6553 - val_loss: 0.8193 - val_accuracy: 0.3266\n",
            "Epoch 10/50\n",
            "74/74 [==============================] - 11s 153ms/step - loss: 0.6451 - accuracy: 0.6553 - val_loss: 0.8512 - val_accuracy: 0.3266\n",
            "Epoch 11/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6470 - accuracy: 0.6553 - val_loss: 0.8881 - val_accuracy: 0.3266\n",
            "Epoch 12/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6445 - accuracy: 0.6553 - val_loss: 0.8513 - val_accuracy: 0.3266\n",
            "Epoch 13/50\n",
            "74/74 [==============================] - 11s 147ms/step - loss: 0.6451 - accuracy: 0.6553 - val_loss: 0.8677 - val_accuracy: 0.3266\n",
            "Epoch 14/50\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6443 - accuracy: 0.6553 - val_loss: 0.8663 - val_accuracy: 0.3266\n",
            "Epoch 15/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6456 - accuracy: 0.6553 - val_loss: 0.8462 - val_accuracy: 0.3266\n",
            "Epoch 16/50\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6451 - accuracy: 0.6553 - val_loss: 0.8487 - val_accuracy: 0.3266\n",
            "Epoch 17/50\n",
            "74/74 [==============================] - 12s 159ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8516 - val_accuracy: 0.3266\n",
            "Epoch 18/50\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6459 - accuracy: 0.6553 - val_loss: 0.8775 - val_accuracy: 0.3266\n",
            "Epoch 19/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8771 - val_accuracy: 0.3266\n",
            "Epoch 20/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8638 - val_accuracy: 0.3266\n",
            "Epoch 21/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8467 - val_accuracy: 0.3266\n",
            "Epoch 22/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8446 - val_accuracy: 0.3266\n",
            "Epoch 23/50\n",
            "74/74 [==============================] - 11s 152ms/step - loss: 0.6454 - accuracy: 0.6553 - val_loss: 0.8698 - val_accuracy: 0.3266\n",
            "Epoch 24/50\n",
            "74/74 [==============================] - 11s 150ms/step - loss: 0.6456 - accuracy: 0.6553 - val_loss: 0.8435 - val_accuracy: 0.3266\n",
            "Epoch 25/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6456 - accuracy: 0.6553 - val_loss: 0.8423 - val_accuracy: 0.3266\n",
            "Epoch 26/50\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6447 - accuracy: 0.6553 - val_loss: 0.8648 - val_accuracy: 0.3266\n",
            "Epoch 27/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6454 - accuracy: 0.6553 - val_loss: 0.8755 - val_accuracy: 0.3266\n",
            "Epoch 28/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6444 - accuracy: 0.6553 - val_loss: 0.8201 - val_accuracy: 0.3266\n",
            "Epoch 29/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6455 - accuracy: 0.6553 - val_loss: 0.8524 - val_accuracy: 0.3266\n",
            "Epoch 30/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8318 - val_accuracy: 0.3266\n",
            "Epoch 31/50\n",
            "74/74 [==============================] - 12s 161ms/step - loss: 0.6449 - accuracy: 0.6553 - val_loss: 0.8727 - val_accuracy: 0.3266\n",
            "Epoch 32/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6449 - accuracy: 0.6553 - val_loss: 0.8427 - val_accuracy: 0.3266\n",
            "Epoch 33/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6449 - accuracy: 0.6553 - val_loss: 0.8774 - val_accuracy: 0.3266\n",
            "Epoch 34/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6453 - accuracy: 0.6553 - val_loss: 0.8620 - val_accuracy: 0.3266\n",
            "Epoch 35/50\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6452 - accuracy: 0.6553 - val_loss: 0.8450 - val_accuracy: 0.3266\n",
            "Epoch 36/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6456 - accuracy: 0.6553 - val_loss: 0.8295 - val_accuracy: 0.3266\n",
            "Epoch 37/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6457 - accuracy: 0.6553 - val_loss: 0.9087 - val_accuracy: 0.3266\n",
            "Epoch 38/50\n",
            "74/74 [==============================] - 11s 153ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.9010 - val_accuracy: 0.3266\n",
            "Epoch 39/50\n",
            "74/74 [==============================] - 11s 151ms/step - loss: 0.6450 - accuracy: 0.6553 - val_loss: 0.8888 - val_accuracy: 0.3266\n",
            "Epoch 40/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6452 - accuracy: 0.6553 - val_loss: 0.8928 - val_accuracy: 0.3266\n",
            "Epoch 41/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6455 - accuracy: 0.6553 - val_loss: 0.8487 - val_accuracy: 0.3266\n",
            "Epoch 42/50\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6448 - accuracy: 0.6553 - val_loss: 0.8528 - val_accuracy: 0.3266\n",
            "Epoch 43/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6451 - accuracy: 0.6553 - val_loss: 0.8560 - val_accuracy: 0.3266\n",
            "Epoch 44/50\n",
            "74/74 [==============================] - 11s 154ms/step - loss: 0.6445 - accuracy: 0.6553 - val_loss: 0.9069 - val_accuracy: 0.3266\n",
            "Epoch 45/50\n",
            "74/74 [==============================] - 12s 155ms/step - loss: 0.6447 - accuracy: 0.6553 - val_loss: 0.8472 - val_accuracy: 0.3266\n",
            "Epoch 46/50\n",
            "74/74 [==============================] - 11s 148ms/step - loss: 0.6446 - accuracy: 0.6553 - val_loss: 0.8894 - val_accuracy: 0.3266\n",
            "Epoch 47/50\n",
            "74/74 [==============================] - 11s 150ms/step - loss: 0.6447 - accuracy: 0.6553 - val_loss: 0.9051 - val_accuracy: 0.3266\n",
            "Epoch 48/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6455 - accuracy: 0.6553 - val_loss: 0.8868 - val_accuracy: 0.3266\n",
            "Epoch 49/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6457 - accuracy: 0.6553 - val_loss: 0.8562 - val_accuracy: 0.3266\n",
            "Epoch 50/50\n",
            "74/74 [==============================] - 11s 149ms/step - loss: 0.6466 - accuracy: 0.6553 - val_loss: 0.8649 - val_accuracy: 0.3266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Analysis\n",
        "\n",
        "What did you discover? What insights/recommendations do you have? What did you find that was interesting? Which model was your best model, which models didn't work well? Why do you think this is? In general, I want a discussion of your experiment, the results, and what they mean."
      ],
      "metadata": {
        "id": "2Qu9bYPLmiv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I made CNN models and they all appear to be underfitting. We know this because our training accuracy is high especially in our first model, but our testing accuracy is not good at all. Our first model has two layers and had a training accuracy of 91.32 and a training accuracy of 36.33% and this was our best model.\n",
        "\n",
        "Next, I did research as to why our model might be underfitting. I found three reasons to try and tune. First, was to use the activation 'relu', which we were already using. Second, was to add more layers because we might not have enough depth for our model to make an accurate prediction. When I tried this on our second model with 2 added layers, it didn't make our model better, but worse. This really confused me because I thought more depth would improve our testing accuracy. Next, these first two models showed that our model wasn't learning, so I thought it might be helpful to change the learning rate. For our third model, I kept the depth at what it was because I still thought it would be helpful with a higher learn rate. First, I started with 5%, then 1%, and lastly .005%, but all of these different learn rates did not improve our model. Ultimately, this made our default CNN model the best because it had the highest training and testing accuracy. As to why my tuned models didn't work, I believe it has to do with the fact that my model isn't learning, but I was unable to fix this issue.\n",
        "\n",
        "As to my insights and recommendations, I believe more research and tuning is needed to be able to get any valuable insight and recommendations. I belieive this because our accuracy is so low for predicting osteoarthritis that it wouldn't help us predict anything.\n",
        "\n",
        "Lastly, I found it interesting and was surprised that I was wasn't able to build a usable and workable model. One theory I have is that it may just be hard to differentiate between a normal knee and a knee with osteoarthritis because when I looked at the normal knee and osteoarthritis knees, I couldn't see a difference. Thus, to achieve an accurate model, it may take more advanced knowledge of tuning CNN's than I have. In the future, I would like to do more research and see if I am able to tune our model better."
      ],
      "metadata": {
        "id": "k17sKBZUmqIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Bumps in the Road\n",
        "What challenges did you encounter? How did you overcome these challenges?"
      ],
      "metadata": {
        "id": "TemAuKxlm6dQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "My first challenge was reading in the data. When I first ran in my model it was giving me 100% for training and testing, which I think was happening because the path for this dataset is test/test instead of just test/. Once I changed this, I got a more reasonable model because it didn't seem plausible to be getting 100% after 1 epoch with a default model.\n",
        "\n",
        "My biggest challenge was the tuning. I was unable to get a good, working model. I tried running 6 or 7 different models, but on every one I was not able to get my model to stop underfitting. Eventually, I had to change it quits because of how much time it was taking to run these models. In the future, I would like to research more and see if I can get a better model. The way I overcame these challenges was that I researched and tried different strategies to improve my model. Even though they didn't work, I still put in a lot of effort and I think this was a great learning experience.\n",
        "\n",
        "\n",
        "Below is the link I used for searching how to better tune a CNN:\n",
        "\n",
        "https://towardsdatascience.com/fine-tuning-a-cnn-model-for-image-classification-a886e4b539b3\n"
      ],
      "metadata": {
        "id": "zXEVEG9FnHgQ"
      }
    }
  ]
}